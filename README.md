## $5 Tech Unlocked 2021!
[Buy and download this product for only $5 on PacktPub.com](https://www.packtpub.com/)
-----
*The $5 campaign         runs from __December 15th 2020__ to __January 13th 2021.__*

# Big Data Processing using Apache Spark [Video]

This is the code repository for [Big Data Processing using Apache Spark [Video]](https://www.packtpub.com/big-data-and-business-intelligence/big-data-processing-using-apache-spark-video?utm_source=github&utm_medium=repository&utm_campaign=9781788398367), published by [Packt](https://www.packtpub.com/?utm_source=github). It contains all the supporting project files necessary to work through the video course from start to finish.

## About the Video Course

Every year we have a big increment of data that we need to store and analyze. When we want to aggregate all data about our users and analyze that data to find insights from it, terabytes of data undergo processing. To be able to process such amounts of data, we need to use a technology that can distribute multiple computations and make them more efficient. Apache Spark is a technology that allows us to process big data leading to faster and scalable processing.

In this course, we will learn how to leverage Apache Spark to be able to process big data quickly. We will cover the basics of Spark API and its architecture in detail. In the second section of the course, we will learn about Data Mining and Data Cleaning, wherein we will look at the Input Data Structure and how Input data is loaded In the third section we will be writing actual jobs that analyze data. By the end of the course, you will have sound understanding of the Spark framework which will help you in writing the code understand the processing of big data.


 <H2>What You Will Learn</H2>

<DIV class=book-info-will-learn-text>

<UL>

<LI>Understand Spark API and its Architecture. 

<LI>Know the difference between RDD and DataFrame API. 

<LI>Learn to join big amounts of data. 

<LI>Start a project using Apache Spark. 

<LI>Discover how to write efficient jobs using Apache Spark. 

<LI>Test Spark code correctly 

<LI>Leverage Apache Spark to process big data faster. </LI></UL></DIV>


 


## Instructions and Navigation

### Assumed Knowledge

To fully benefit from the coverage included in this course, you will need:<br/>

If you are a software Engineer interested in Big Data Processing then this course is for you. A basic understanding and functional knowledge of Apache Spark and big data are required.

### Technical Requirements

This course has the following software requirements:<br/>

This course has the following software requirements:


 


modern laptop/cpu

IDE IntelliJ IDEA, Atom

JDK


 


Software Required:

Apache Spark, Scala, Python, Java


 


OS:

Windows, Mac OS X, and Linux (Any)


 


## Related Products

* [Big Data Analytics Projects with Apache Spark [Video]](https://www.packtpub.com/big-data-and-business-intelligence/big-data-analytics-projects-apache-spark-video?utm_source=github&utm_medium=repository&utm_campaign=9781789132373)


 


* [Distributed Deep Learning with Apache Spark [Video]](https://www.packtpub.com/big-data-and-business-intelligence/distributed-deep-learning-apache-spark-video?utm_source=github&utm_medium=repository&utm_campaign=9781838553838)


 


* [Deep Learning with Apache Spark [Video]](https://www.packtpub.com/big-data-and-business-intelligence/deep-learning-apache-spark-video?utm_source=github&utm_medium=repository&utm_campaign=9781787286689)
